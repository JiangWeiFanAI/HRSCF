{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fro HRFSR_v1\n",
    "\n",
    "from datetime import timedelta, date, datetime\n",
    "import os\n",
    "import sys\n",
    "sys.append(\"../\")\n",
    "import util.\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "interval_band=[90,75,50,25,10]\n",
    "\n",
    "class aaa(object):\n",
    "    def __init__(self,lead,year_generate=1997):\n",
    "        self.ensemble_access=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']\n",
    "        self.lead_time=lead\n",
    "        self.year_generate=year_generate\n",
    "        self.files=self.get_filename_with_time_order()\n",
    "    def get_filename_with_time_order(self):\n",
    "        _files = []\n",
    "        for mm in range(1,13):\n",
    "            for dd in [1,9,17,25]:\n",
    "#                 for i in range(self.lead_time,self.lead_time+1):\n",
    "#                 for en in ['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']:\n",
    "                path=[]\n",
    "                date_time=date(self.year_generate, mm, dd)\n",
    "                barra_date=date_time+timedelta(self.lead_time)\n",
    "                path.append(date_time)\n",
    "                path.append(barra_date)\n",
    "                path.append(self.lead_time)\n",
    "                _files.append(path)\n",
    "        return _files\n",
    "    def __getitem__(self,idx):\n",
    "        return self.files[idx]\n",
    "\n",
    "def load_climatology_data(l,measurement ,year_generate,climatology_num):\n",
    "    data=aaa(l,year_generate)\n",
    "    climtology_lead_time=[]\n",
    "    climatology_data=np.load('./save/'+measurement+'/climatology/climatology_'+str(year_generate)+'_all_lead_time_windows_'+str(climatology_num)+'.npy')\n",
    "#     print(climatology_data.shape)\n",
    "    dates_needs=date_range(date(year_generate, 1, 1),date(year_generate+1, 7, 29))\n",
    "    date_map=np.array(dates_needs)\n",
    "    for _,target_date,_ in data.files:\n",
    "        idx=np.where(date_map==target_date)[0]\n",
    "        climtology_lead_time.append(climatology_data[idx][0])\n",
    "    return np.array(climtology_lead_time)\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    \"\"\"This function takes a start date and an end date as datetime date objects.\n",
    "    It returns a list of dates for each date in order starting at the first date and ending with the last date\"\"\"\n",
    "    return [start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "\n",
    "def table_csv_confidence(data_np,file_dir):\n",
    "    with open(file_dir+'.csv', \"w\", newline='') as file:\n",
    "        csv_file = csv.writer(file)\n",
    "        head = [\"leading\",str(interval_band[0]),str(interval_band[1]),str(interval_band[2]),str(interval_band[3]),str(interval_band[4])]\n",
    "        csv_file.writerow(head)\n",
    "\n",
    "        for lead_time in range(217):\n",
    "            line=[lead_time,data_np[0,lead_time],data_np[1,lead_time],data_np[2,lead_time],data_np[3,lead_time],data_np[4,lead_time]]\n",
    "\n",
    "            csv_file.writerow(line)\n",
    "\n",
    "def draw_plot(data,name,ylim_set=(-0.6,0.5)):\n",
    "        x=list(range(1,218))\n",
    "        data_np=np.array(data)\n",
    "        # plt.plot(x,mean_my,label=\"\",color=\"b\")#mean\n",
    "        plt.figure(dpi=100,figsize=(15,5))\n",
    "        plt.plot(x,data_np[2,:],label=\"\",color=\"r\")#median\n",
    "        plt.plot(x,[0]*217,color=\"#000000\")\n",
    "        plt.fill_between(x,data_np[0,:],data_np[1,:],color=\"#cacaca\")\n",
    "        plt.fill_between(x,data_np[1,:],data_np[2,:],color=\"#989898\")\n",
    "        plt.fill_between(x,data_np[2,:],data_np[3,:],color=\"#989898\")\n",
    "        plt.fill_between(x,data_np[3,:],data_np[4,:],color=\"#cacaca\")\n",
    "        # plt.xlim(0,217)\n",
    "        # plt.grid()\n",
    "        plt.xlabel(\" Leadtime (day)\")\n",
    "        plt.ylabel(\" CRPS_SS\")\n",
    "        plt.ylim(ylim_set[0],ylim_set[1])\n",
    "        pdf = PdfPages(name+\".pdf\")\n",
    "        pdf.savefig()\n",
    "        pdf.close()\n",
    "        plt.clf()\n",
    "        table_csv_confidence(data_np,name)\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "def save_csv_mean(my_pr=0,my_pr_zg=0,cali=0,BI=0,climat=0,ss_my_pr=0,ss_my_pr_zg=0,ss_cali=0,ss_BI=0,lead=0,file_dir=0,first_init=0,climatology_num=1):\n",
    "    if first_init:\n",
    "        with open('table_mean_'+file_dir+'.csv', \"w\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "            head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(head)\n",
    "    else:\n",
    "        line=[lead,climat.mean(),BI.mean(),my_pr.mean(),my_pr_zg.mean(),cali.mean(),ss_BI.mean(), ss_my_pr.mean(),ss_my_pr_zg.mean(),ss_cali.mean()]\n",
    "        with open('table_mean_'+file_dir+'.csv', \"a\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "#             head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(line) \n",
    "    \n",
    "def save_csv_median(my_pr=0,my_pr_zg=0,cali=0,BI=0,climat=0,ss_my_pr=0,ss_my_pr_zg=0,ss_cali=0,ss_BI=0,lead=0,file_dir=0,first_init=0,climatology_num=1):\n",
    "    if first_init:\n",
    "        with open('table_median_'+file_dir+'.csv', \"w\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "            head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(head)\n",
    "    else:\n",
    "        line=[lead,np.median(climat),np.median(BI),np.median(my_pr),np.median(my_pr_zg),np.median(cali),np.median(ss_BI), np.median(ss_my_pr),np.median(ss_my_pr_zg),np.median(ss_cali)]\n",
    "        with open('table_median_'+file_dir+'.csv', \"a\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "#             head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(line)           \n",
    "            \n",
    "            \n",
    "            \n",
    "def draw_confidence_figure(measurement='crps',climatology_num=1,option='whole',year_generate=2010):\n",
    "    \n",
    "    if option == \"whole\":\n",
    "        dpt.\n",
    "        \n",
    "        file_path='../save/'+measurement+'/results/'+option+'/climatology_'+str(climatology_num)+'/whole_climatology_' +str(year_generate)+'_' +str(climatology_num)\n",
    "        \n",
    "        \n",
    "        save_csv_mean(file_dir=file_path,first_init=1)\n",
    "        save_csv_median(file_dir=file_path,first_init=1)\n",
    "\n",
    "        land=np.load(\"../save/mae/1997/lead_time_\"+str(216)+\".npy\").mean(0)\n",
    "        x=list(range(1,218))\n",
    "\n",
    "\n",
    "\n",
    "        data_my_pr_against_climatology=[]\n",
    "        data_my_pr_zg_against_climatology=[]\n",
    "        data_cali_against_climatology=[]\n",
    "        data_BI_against_climatology=[]\n",
    "\n",
    "        \n",
    "        mean_my=[]\n",
    "\n",
    "        for q in interval_band:\n",
    "            my_pr_against_climatology=[]\n",
    "            my_pr_zg_against_climatology=[]\n",
    "            cali_against_climatology=[]\n",
    "            BI_against_climatology=[]\n",
    "            \n",
    "            for lead_time in range(217):\n",
    "                my_pr=np.load(\"./save/\"+measurement+\"/vdsrd/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                my_pr_zg=np.load(\"./save/\"+measurement+\"/vdsrd2/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "                BI=np.load(\"./save/\"+measurement+\"/bi_217/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                climat=load_climatology_data(lead_time,measurement,year_generate,climatology_num).mean(0)[~np.isinf(land)]\n",
    "                cali=np.load(\"./save/\"+measurement+\"/calibration/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "\n",
    "                ss_my_pr= 1-my_pr/climat\n",
    "                ss_my_pr_zg=1-my_pr_zg/climat\n",
    "                ss_cali=1-cali/climat\n",
    "                ss_bi=1-BI/climat\n",
    "                \n",
    "                if q==interval_band[0]: #save four module crps and ss_crps\n",
    "                    save_csv_mean(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path ,climatology_num)\n",
    "                    save_csv_median(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path,climatology_num)\n",
    "\n",
    "                my_pr_against_climatology.append(np.percentile( ss_my_pr,q))\n",
    "                my_pr_zg_against_climatology.append(np.percentile(ss_my_pr_zg ,q))\n",
    "                cali_against_climatology.append(np.percentile( ss_cali,q))\n",
    "                BI_against_climatology.append(np.percentile(ss_bi ,q))\n",
    "\n",
    "            data_my_pr_against_climatology.append(my_pr_against_climatology)\n",
    "            data_my_pr_zg_against_climatology.append(my_pr_zg_against_climatology)\n",
    "            data_cali_against_climatology.append(cali_against_climatology)\n",
    "            data_BI_against_climatology.append(BI_against_climatology)\n",
    "\n",
    "\n",
    "        draw_plot(data_my_pr_against_climatology,'DL_pr_only_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_my_pr_zg_against_climatology,'DL_pr_zg_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_cali_against_climatology,'calibration_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_BI_against_climatology,'BI_against_climatology_'+str(year_generate)+'_'+option) \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        file_path='station_climatology_'+str(year_generate)+'_' +str(climatology_num)\n",
    "        save_csv_mean(file_dir=file_path,first_init=1)\n",
    "        save_csv_median(file_dir=file_path,first_init=1)\n",
    "        \n",
    "        if option=='50':\n",
    "            from constant_param import station_50_index_for_size_of_hr_sr as station_dict\n",
    "        if option=='214':\n",
    "            from constant_param import station_214_index_for_size_of_hr_sr as station_dict\n",
    "            \n",
    "        land=np.load(\"./save/crps/whole_calibration/2012/lead_time\"+str(0)+\"_whole.npy\").mean(0)\n",
    "        station_index=np.zeros((land.shape))\n",
    "        for i in station_dict.keys():\n",
    "            station_index[station_dict[i]]=1\n",
    "            \n",
    "        x=list(range(1,218))\n",
    "\n",
    "\n",
    "\n",
    "        data_my_pr_against_climatology=[]\n",
    "        data_my_pr_zg_against_climatology=[]\n",
    "        data_cali_against_climatology=[]\n",
    "        data_BI_against_climatology=[]\n",
    "\n",
    "        \n",
    "        mean_my=[]\n",
    "        # for i in range(30):\n",
    "        #     a=np.load(\"./save_vdsr_pr_best_test/lead_time\"+str(i)+\"_50station_my.npy\")\n",
    "        #     mean_my.append(1-a.mean()/station50_int[i])\n",
    "        # for q in [95,75,50,25,5]:\n",
    "        #     data[q]=[]\n",
    "        for q in interval_band:\n",
    "            my_pr_against_climatology=[]\n",
    "            my_pr_zg_against_climatology=[]\n",
    "            cali_against_climatology=[]\n",
    "            BI_against_climatology=[]\n",
    "            \n",
    "            for lead_time in range(217):\n",
    "                if year_generate==2012:\n",
    "                    my_pr=np.load(\"./save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    #!!!!!!!!my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/wjdata/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[station_index==1]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[station_index==1]\n",
    "\n",
    "                else:\n",
    "                    my_pr=np.load(\"/scratch/iu60/mc7437/baseline/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[station_index==1]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[station_index==1]\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                \n",
    "\n",
    "                \n",
    "                ss_my_pr= 1-my_pr/climat\n",
    "                ss_my_pr_zg=1-my_pr_zg/climat\n",
    "                ss_cali=1-cali/climat\n",
    "                ss_bi=1-BI/climat\n",
    "                \n",
    "                if q==interval_band[0]: #save four module crps and ss_crps\n",
    "                    save_csv_mean(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "                    save_csv_median(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "\n",
    "                my_pr_against_climatology.append(np.percentile( 1-my_pr/climat,q))\n",
    "                my_pr_zg_against_climatology.append(np.percentile( 1-my_pr_zg/climat,q))\n",
    "                cali_against_climatology.append(np.percentile( 1-cali/climat,q))\n",
    "                BI_against_climatology.append(np.percentile( 1-BI/climat,q))\n",
    "\n",
    "            data_my_pr_against_climatology.append(my_pr_against_climatology)\n",
    "            data_my_pr_zg_against_climatology.append(my_pr_zg_against_climatology)\n",
    "            data_cali_against_climatology.append(cali_against_climatology)\n",
    "            data_BI_against_climatology.append(BI_against_climatology)\n",
    "\n",
    "        draw_plot(data_my_pr_against_climatology,'DL_pr_only_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_my_pr_zg_against_climatology,'DL_pr_zg_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_cali_against_climatology,'calibration_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_BI_against_climatology,'BI_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "                                     \n",
    "draw_confidence_figure(option='whole',year_generate=2012)\n",
    "draw_confidence_figure(option='50',year_generate=2012)\n",
    "draw_confidence_figure(option='whole',year_generate=2010)\n",
    "draw_confidence_figure(option='50',year_generate=2010)\n",
    "draw_confidence_figure(option='whole',year_generate=1997)\n",
    "draw_confidence_figure(option='50',year_generate=1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T06:55:48.968478Z",
     "start_time": "2021-05-22T06:55:48.935839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58209,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# land=np.load(\"../save/crps/whole_calibration/lead_time\"+str(216)+\"_whole.npy\").mean(0)\n",
    "land=np.load(\"../save/mae/1997/lead_time_\"+str(216)+\".npy\").mean(0)\n",
    "land[~np.isinf(land)].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vdsr\n",
    "\n",
    "\n",
    "from datetime import timedelta, date, datetime\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "climatology_num=11\n",
    "interval_band=[90,75,50,25,10]\n",
    "\n",
    "class aaa(object):\n",
    "    def __init__(self,lead,year_generate=1997):\n",
    "        self.ensemble_access=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']\n",
    "        self.lead_time=lead\n",
    "        self.year_generate=year_generate\n",
    "        self.files=self.get_filename_with_time_order()\n",
    "    def get_filename_with_time_order(self):\n",
    "        _files = []\n",
    "        for mm in range(1,13):\n",
    "            for dd in [1,9,17,25]:\n",
    "#                 for i in range(self.lead_time,self.lead_time+1):\n",
    "#                 for en in ['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']:\n",
    "                path=[]\n",
    "                date_time=date(self.year_generate, mm, dd)\n",
    "                barra_date=date_time+timedelta(self.lead_time)\n",
    "                path.append(date_time)\n",
    "                path.append(barra_date)\n",
    "                path.append(self.lead_time)\n",
    "                _files.append(path)\n",
    "        return _files\n",
    "    def __getitem__(self,idx):\n",
    "        return self.files[idx]\n",
    "\n",
    "def load_climatology_data(l,year_generate):\n",
    "    data=aaa(l,year_generate)\n",
    "    climtology_lead_time=[]\n",
    "    climatology_data=np.load('./save/crps/climatology_'+str(year_generate)+'_all_lead_time_windows_'+str(climatology_num)+'.npy')\n",
    "#     print(climatology_data.shape)\n",
    "    dates_needs=date_range(date(year_generate, 1, 1),date(year_generate+1, 7, 29))\n",
    "    date_map=np.array(dates_needs)\n",
    "    for _,target_date,_ in data.files:\n",
    "        idx=np.where(date_map==target_date)[0]\n",
    "        climtology_lead_time.append(climatology_data[idx][0])\n",
    "    return np.array(climtology_lead_time)\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    \"\"\"This function takes a start date and an end date as datetime date objects.\n",
    "    It returns a list of dates for each date in order starting at the first date and ending with the last date\"\"\"\n",
    "    return [start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "\n",
    "def table_csv_confidence(data_np,file_dir):\n",
    "    with open(file_dir+'.csv', \"w\", newline='') as file:\n",
    "        csv_file = csv.writer(file)\n",
    "        head = [\"leading\",str(interval_band[0]),str(interval_band[1]),str(interval_band[2]),str(interval_band[3]),str(interval_band[4])]\n",
    "        csv_file.writerow(head)\n",
    "\n",
    "        for lead_time in range(217):\n",
    "            line=[lead_time,data_np[0,lead_time],data_np[1,lead_time],data_np[2,lead_time],data_np[3,lead_time],data_np[4,lead_time]]\n",
    "\n",
    "            csv_file.writerow(line)\n",
    "\n",
    "def draw_plot(data,name,ylim_set=(-0.6,0.5)):\n",
    "        x=list(range(1,218))\n",
    "        data_np=np.array(data)\n",
    "        # plt.plot(x,mean_my,label=\"\",color=\"b\")#mean\n",
    "        plt.figure(dpi=100,figsize=(15,5))\n",
    "        plt.plot(x,data_np[2,:],label=\"\",color=\"r\")#median\n",
    "        plt.plot(x,[0]*217,color=\"#000000\")\n",
    "        plt.fill_between(x,data_np[0,:],data_np[1,:],color=\"#cacaca\")\n",
    "        plt.fill_between(x,data_np[1,:],data_np[2,:],color=\"#989898\")\n",
    "        plt.fill_between(x,data_np[2,:],data_np[3,:],color=\"#989898\")\n",
    "        plt.fill_between(x,data_np[3,:],data_np[4,:],color=\"#cacaca\")\n",
    "        # plt.xlim(0,217)\n",
    "        # plt.grid()\n",
    "        plt.xlabel(\" Leadtime (day)\")\n",
    "        plt.ylabel(\" CRPS_SS\")\n",
    "        plt.ylim(ylim_set[0],ylim_set[1])\n",
    "        pdf = PdfPages(name+\".pdf\")\n",
    "        pdf.savefig()\n",
    "        pdf.close()\n",
    "        plt.clf()\n",
    "        table_csv_confidence(data_np,name)\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "def save_csv_mean(my_pr=0,my_pr_zg=0,cali=0,BI=0,climat=0,ss_my_pr=0,ss_my_pr_zg=0,ss_cali=0,ss_BI=0,lead=0,file_dir=0,first_init=0):\n",
    "    if first_init:\n",
    "        with open('table_mean_'+file_dir+'.csv', \"w\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "            head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(head)\n",
    "    else:\n",
    "        line=[lead,climat.mean(),BI.mean(),my_pr.mean(),my_pr_zg.mean(),cali.mean(),ss_BI.mean(), ss_my_pr.mean(),ss_my_pr_zg.mean(),ss_cali.mean()]\n",
    "        with open('table_mean_'+file_dir+'.csv', \"a\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "#             head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(line) \n",
    "    \n",
    "def save_csv_median(my_pr=0,my_pr_zg=0,cali=0,BI=0,climat=0,ss_my_pr=0,ss_my_pr_zg=0,ss_cali=0,ss_BI=0,lead=0,file_dir=0,first_init=0):\n",
    "    if first_init:\n",
    "        with open('table_median_'+file_dir+'.csv', \"w\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "            head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(head)\n",
    "    else:\n",
    "        line=[lead,np.median(climat),np.median(BI),np.median(my_pr),np.median(my_pr_zg),np.median(cali),np.median(ss_BI), np.median(ss_my_pr),np.median(ss_my_pr_zg),np.median(ss_cali)]\n",
    "        with open('table_median_'+file_dir+'.csv', \"a\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "#             head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(line)           \n",
    "            \n",
    "            \n",
    "            \n",
    "def draw_confidence_figure(option='whole',year_generate=2010):\n",
    "    \n",
    "    if option == \"whole\":\n",
    "        file_path='whole_climatology_' +str(year_generate)+'_' +str(climatology_num)\n",
    "        \n",
    "        \n",
    "        save_csv_mean(file_dir=file_path,first_init=1)\n",
    "        save_csv_median(file_dir=file_path,first_init=1)\n",
    "\n",
    "        land=np.load(\"./save/crps/whole_calibration/2012/lead_time\"+str(0)+\"_whole.npy\").mean(0)\n",
    "        x=list(range(1,218))\n",
    "\n",
    "\n",
    "\n",
    "        data_my_pr_against_climatology=[]\n",
    "        data_my_pr_zg_against_climatology=[]\n",
    "        data_cali_against_climatology=[]\n",
    "        data_BI_against_climatology=[]\n",
    "\n",
    "        \n",
    "        mean_my=[]\n",
    "\n",
    "        for q in interval_band:\n",
    "            my_pr_against_climatology=[]\n",
    "            my_pr_zg_against_climatology=[]\n",
    "            cali_against_climatology=[]\n",
    "            BI_against_climatology=[]\n",
    "            \n",
    "            for lead_time in range(217):\n",
    "                if year_generate==2012:\n",
    "                    my_pr=np.load(\"./save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/wjdata/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[~np.isinf(land)]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "                else:\n",
    "                    my_pr=np.load(\"/scratch/iu60/mc7437/baseline/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[~np.isinf(land)]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[~np.isinf(land)]\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                \n",
    "                ss_my_pr= 1-my_pr/climat\n",
    "                ss_my_pr_zg=1-my_pr_zg/climat\n",
    "                ss_cali=1-cali/climat\n",
    "                ss_bi=1-BI/climat\n",
    "                \n",
    "                if q==interval_band[0]: #save four module crps and ss_crps\n",
    "                    save_csv_mean(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "                    save_csv_median(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path)\n",
    "\n",
    "                my_pr_against_climatology.append(np.percentile( ss_my_pr,q))\n",
    "                my_pr_zg_against_climatology.append(np.percentile(ss_my_pr_zg ,q))\n",
    "                cali_against_climatology.append(np.percentile( ss_cali,q))\n",
    "                BI_against_climatology.append(np.percentile(ss_bi ,q))\n",
    "\n",
    "            data_my_pr_against_climatology.append(my_pr_against_climatology)\n",
    "            data_my_pr_zg_against_climatology.append(my_pr_zg_against_climatology)\n",
    "            data_cali_against_climatology.append(cali_against_climatology)\n",
    "            data_BI_against_climatology.append(BI_against_climatology)\n",
    "\n",
    "\n",
    "        draw_plot(data_my_pr_against_climatology,'DL_pr_only_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_my_pr_zg_against_climatology,'DL_pr_zg_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_cali_against_climatology,'calibration_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_BI_against_climatology,'BI_against_climatology_'+str(year_generate)+'_'+option) \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        file_path='station_climatology_'+str(year_generate)+'_' +str(climatology_num)\n",
    "        save_csv_mean(file_dir=file_path,first_init=1)\n",
    "        save_csv_median(file_dir=file_path,first_init=1)\n",
    "        \n",
    "        if option=='50':\n",
    "            from constant_param import station_50_index_for_size_of_hr_sr as station_dict\n",
    "        if option=='214':\n",
    "            from constant_param import station_214_index_for_size_of_hr_sr as station_dict\n",
    "            \n",
    "        land=np.load(\"./save/crps/whole_calibration/2012/lead_time\"+str(0)+\"_whole.npy\").mean(0)\n",
    "        station_index=np.zeros((land.shape))\n",
    "        for i in station_dict.keys():\n",
    "            station_index[station_dict[i]]=1\n",
    "            \n",
    "        x=list(range(1,218))\n",
    "\n",
    "\n",
    "\n",
    "        data_my_pr_against_climatology=[]\n",
    "        data_my_pr_zg_against_climatology=[]\n",
    "        data_cali_against_climatology=[]\n",
    "        data_BI_against_climatology=[]\n",
    "\n",
    "        \n",
    "        mean_my=[]\n",
    "        # for i in range(30):\n",
    "        #     a=np.load(\"./save_vdsr_pr_best_test/lead_time\"+str(i)+\"_50station_my.npy\")\n",
    "        #     mean_my.append(1-a.mean()/station50_int[i])\n",
    "        # for q in [95,75,50,25,5]:\n",
    "        #     data[q]=[]\n",
    "        for q in interval_band:\n",
    "            my_pr_against_climatology=[]\n",
    "            my_pr_zg_against_climatology=[]\n",
    "            cali_against_climatology=[]\n",
    "            BI_against_climatology=[]\n",
    "            \n",
    "            for lead_time in range(217):\n",
    "                if year_generate==2012:\n",
    "                    my_pr=np.load(\"./save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    #!!!!!!!!my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/wjdata/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[station_index==1]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[station_index==1]\n",
    "\n",
    "                else:\n",
    "                    my_pr=np.load(\"/scratch/iu60/mc7437/baseline/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[station_index==1]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[station_index==1]\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[station_index==1]\n",
    "                \n",
    "\n",
    "                \n",
    "                ss_my_pr= 1-my_pr/climat\n",
    "                ss_my_pr_zg=1-my_pr_zg/climat\n",
    "                ss_cali=1-cali/climat\n",
    "                ss_bi=1-BI/climat\n",
    "                \n",
    "                if q==interval_band[0]: #save four module crps and ss_crps\n",
    "                    save_csv_mean(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "                    save_csv_median(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "\n",
    "                my_pr_against_climatology.append(np.percentile( 1-my_pr/climat,q))\n",
    "                my_pr_zg_against_climatology.append(np.percentile( 1-my_pr_zg/climat,q))\n",
    "                cali_against_climatology.append(np.percentile( 1-cali/climat,q))\n",
    "                BI_against_climatology.append(np.percentile( 1-BI/climat,q))\n",
    "\n",
    "            data_my_pr_against_climatology.append(my_pr_against_climatology)\n",
    "            data_my_pr_zg_against_climatology.append(my_pr_zg_against_climatology)\n",
    "            data_cali_against_climatology.append(cali_against_climatology)\n",
    "            data_BI_against_climatology.append(BI_against_climatology)\n",
    "\n",
    "        draw_plot(data_my_pr_against_climatology,'DL_pr_only_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_my_pr_zg_against_climatology,'DL_pr_zg_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_cali_against_climatology,'calibration_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        draw_plot(data_BI_against_climatology,'BI_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "                                     \n",
    "draw_confidence_figure(option='whole',year_generate=2012)\n",
    "draw_confidence_figure(option='50',year_generate=2012)\n",
    "draw_confidence_figure(option='whole',year_generate=2010)\n",
    "draw_confidence_figure(option='50',year_generate=2010)\n",
    "draw_confidence_figure(option='whole',year_generate=1997)\n",
    "draw_confidence_figure(option='50',year_generate=1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-07T03:29:36.629150Z",
     "start_time": "2021-04-07T03:29:27.372078Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import util.data_processing_tool as dpt\n",
    "from datetime import timedelta, date, datetime\n",
    "# import args_parameter as args\n",
    "import torch,torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset,random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import time\n",
    "import xarray as xr\n",
    "from PIL import Image\n",
    "\n",
    "class ACCESS_BARRA_Probabilistic(Dataset):\n",
    "    '''\n",
    "\n",
    "    read 11 probalistic forecast\n",
    "   \n",
    "    '''\n",
    "    def __init__(self,start_date=date(1990, 1, 1),end_date=date(1990,12 , 31),regin=\"AUS\",lr_transform=None,hr_transform=None,shuffle=True,args=None):\n",
    "#         print(\"=> BARRA_R & ACCESS_S1 loading\")\n",
    "#         print(\"=> from \"+start_date.strftime(\"%Y/%m/%d\")+\" to \"+end_date.strftime(\"%Y/%m/%d\")+\"\")\n",
    "        self.file_BARRA_dir = args.file_BARRA_dir\n",
    "        self.file_ACCESS_dir = args.file_ACCESS_dir\n",
    "        self.args=args\n",
    "        \n",
    "        self.lr_transform = lr_transform\n",
    "        self.hr_transform = hr_transform\n",
    "\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        \n",
    "        self.regin = regin\n",
    "        self.leading_time_we_use=args.leading_time_we_use\n",
    "\n",
    "        self.ensemble_access=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']\n",
    "        self.ensemble=[]\n",
    "        for i in range(args.ensemble):\n",
    "            self.ensemble.append(self.ensemble_access[i])\n",
    "                \n",
    "        self.dates = self.date_range(start_date, end_date)\n",
    "        \n",
    "        \n",
    "        self.filename_list=self.get_filename_with_time_order(args.file_ACCESS_dir+\"pr/daily/\")\n",
    "\n",
    "        \n",
    "        _,_,date_for_BARRA,time_leading=self.filename_list[0]\n",
    "        if shuffle:\n",
    "            random.shuffle(self.filename_list)\n",
    "        \n",
    "        data_high=dpt.read_barra_data_fc_get_lat_lon(self.file_BARRA_dir,date_for_BARRA)\n",
    "        self.lat=data_high[1]\n",
    "        self.lon=data_high[1]\n",
    "\n",
    "\n",
    "        self.data_dem=dpt.read_dem(args.file_DEM_dir+\"dem-9s1.tif\")\n",
    "        self.data_dem=self.lr_transform(Image.fromarray(self.data_dem))\n",
    "#         print(type(self.data_dem))\n",
    "        \n",
    "#             data_dem=dpt.add_lat_lon( dpt.read_dem(args.file_DEM_dir+\"dem-9s1.tif\"))\n",
    "#             self.dem_data=dpt.interp_tensor_2d(dpt.map_aust_old(data_dem,xrarray=False) ,self.shape )\n",
    "        \n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filename_list)\n",
    "    \n",
    "\n",
    "    def date_range(self,start_date, end_date):\n",
    "        \"\"\"This function takes a start date and an end date as datetime date objects.\n",
    "        It returns a list of dates for each date in order starting at the first date and ending with the last date\"\"\"\n",
    "        return [start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "    \n",
    "    def get_filename_with_no_time_order(self,rootdir):\n",
    "        '''get filename first and generate label '''\n",
    "        _files = []\n",
    "        list = os.listdir(rootdir) #列出文件夹下所有的目录与文件\n",
    "        for i in range(0,len(list)):\n",
    "            path = os.path.join(rootdir,list[i])\n",
    "            if os.path.isdir(path):\n",
    "                _files.extend(self.get_filename_with_no_time_order(path))\n",
    "            if os.path.isfile(path):\n",
    "                if path[-3:]==\".nc\":\n",
    "                    _files.append(path)\n",
    "        return _files\n",
    "    \n",
    "    def get_filename_with_time_order(self,rootdir):\n",
    "        '''get filename first and generate label ,one different w'''\n",
    "        _files = []\n",
    "        for date in self.dates:\n",
    "            for i in range(self.leading_time_we_use,self.leading_time_we_use+1):\n",
    "            \n",
    "\n",
    "#                 filename=\"da_pr_\"+date.strftime(\"%Y%m%d\")+\"_\"+en+\".nc\"cd\n",
    "#                 access_path=rootdir+en+\"/\"+\"da_pr_\"+date.strftime(\"%Y%m%d\")+\"_\"+en+\".nc\"\n",
    "#                 print(access_path)\n",
    "                for en in self.ensemble:\n",
    "                    access_path=rootdir+en+\"/\"+\"da_pr_\"+date.strftime(\"%Y%m%d\")+\"_\"+en+\".nc\"\n",
    "                    if os.path.exists(access_path):\n",
    "                        \n",
    "                    \n",
    "                        if date==self.end_date and i==1:\n",
    "                            break\n",
    "                        path=[]\n",
    "                        path.append(en)\n",
    "                        barra_date=date+timedelta(i)\n",
    "                        path.append(date)\n",
    "                        path.append(barra_date)\n",
    "                        path.append(i)\n",
    "                        _files.append(path)                   \n",
    "\n",
    "        return _files\n",
    "\n",
    "    def mapping(self,X,min_val=0.,max_val=255.):\n",
    "        Xmin = np.min(X)\n",
    "        Xmax = np.max(X)\n",
    "        #将数据映射到[-1,1]区间 即a=-1，b=1\n",
    "        a = min_val\n",
    "        b = max_val\n",
    "        Y = a + (b-a)/(Xmax-Xmin)*(X-Xmin)\n",
    "        return Y\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        from filename idx get id\n",
    "        return lr,hr\n",
    "        '''\n",
    "        t=time.time()\n",
    "        \n",
    "        #read_data filemame[idx]\n",
    "        en,access_date,barra_date,time_leading=self.filename_list[idx]\n",
    "        \n",
    "\n",
    "        lr=dpt.read_access_data(self.file_ACCESS_dir,en,access_date,time_leading,\"pr\")\n",
    "#         lr=np.expand_dims(lr,axis=2)\n",
    "#         lr=np.expand_dims(self.mapping(lr),axis=2)\n",
    "        label=dpt.read_barra_data_fc(self.file_BARRA_dir,barra_date)\n",
    "\n",
    "        return self.lr_transform(Image.fromarray(lr)),self.data_dem,self.hr_transform(Image.fromarray(label)),torch.tensor(int(en[1:])),torch.tensor(int(access_date.strftime(\"%Y%m%d\"))),torch.tensor(time_leading)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:15:27.845550Z",
     "start_time": "2021-05-12T03:15:27.839086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('e02', 'e11')\n",
      "('e02', 'e09')\n",
      "('e02', 'e07')\n",
      "('e02', 'e01')\n",
      "('e02', 'e06')\n",
      "('e02', 'e02')\n",
      "('e02', 'e03')\n",
      "('e02', 'e10')\n",
      "('e02', 'e08')\n",
      "('e02', 'e04')\n",
      "('e02', 'e05')\n",
      "('e07', 'e11')\n",
      "('e07', 'e09')\n",
      "('e07', 'e07')\n",
      "('e07', 'e01')\n",
      "('e07', 'e06')\n",
      "('e07', 'e02')\n",
      "('e07', 'e03')\n",
      "('e07', 'e10')\n",
      "('e07', 'e08')\n",
      "('e07', 'e04')\n",
      "('e07', 'e05')\n",
      "('e08', 'e11')\n",
      "('e08', 'e09')\n",
      "('e08', 'e07')\n",
      "('e08', 'e01')\n",
      "('e08', 'e06')\n",
      "('e08', 'e02')\n",
      "('e08', 'e03')\n",
      "('e08', 'e10')\n",
      "('e08', 'e08')\n",
      "('e08', 'e04')\n",
      "('e08', 'e05')\n",
      "('e06', 'e11')\n",
      "('e06', 'e09')\n",
      "('e06', 'e07')\n",
      "('e06', 'e01')\n",
      "('e06', 'e06')\n",
      "('e06', 'e02')\n",
      "('e06', 'e03')\n",
      "('e06', 'e10')\n",
      "('e06', 'e08')\n",
      "('e06', 'e04')\n",
      "('e06', 'e05')\n",
      "('e11', 'e11')\n",
      "('e11', 'e09')\n",
      "('e11', 'e07')\n",
      "('e11', 'e01')\n",
      "('e11', 'e06')\n",
      "('e11', 'e02')\n",
      "('e11', 'e03')\n",
      "('e11', 'e10')\n",
      "('e11', 'e08')\n",
      "('e11', 'e04')\n",
      "('e11', 'e05')\n",
      "('e09', 'e11')\n",
      "('e09', 'e09')\n",
      "('e09', 'e07')\n",
      "('e09', 'e01')\n",
      "('e09', 'e06')\n",
      "('e09', 'e02')\n",
      "('e09', 'e03')\n",
      "('e09', 'e10')\n",
      "('e09', 'e08')\n",
      "('e09', 'e04')\n",
      "('e09', 'e05')\n",
      "('e10', 'e11')\n",
      "('e10', 'e09')\n",
      "('e10', 'e07')\n",
      "('e10', 'e01')\n",
      "('e10', 'e06')\n",
      "('e10', 'e02')\n",
      "('e10', 'e03')\n",
      "('e10', 'e10')\n",
      "('e10', 'e08')\n",
      "('e10', 'e04')\n",
      "('e10', 'e05')\n",
      "('e03', 'e11')\n",
      "('e03', 'e09')\n",
      "('e03', 'e07')\n",
      "('e03', 'e01')\n",
      "('e03', 'e06')\n",
      "('e03', 'e02')\n",
      "('e03', 'e03')\n",
      "('e03', 'e10')\n",
      "('e03', 'e08')\n",
      "('e03', 'e04')\n",
      "('e03', 'e05')\n",
      "('e04', 'e11')\n",
      "('e04', 'e09')\n",
      "('e04', 'e07')\n",
      "('e04', 'e01')\n",
      "('e04', 'e06')\n",
      "('e04', 'e02')\n",
      "('e04', 'e03')\n",
      "('e04', 'e10')\n",
      "('e04', 'e08')\n",
      "('e04', 'e04')\n",
      "('e04', 'e05')\n",
      "('e01', 'e11')\n",
      "('e01', 'e09')\n",
      "('e01', 'e07')\n",
      "('e01', 'e01')\n",
      "('e01', 'e06')\n",
      "('e01', 'e02')\n",
      "('e01', 'e03')\n",
      "('e01', 'e10')\n",
      "('e01', 'e08')\n",
      "('e01', 'e04')\n",
      "('e01', 'e05')\n",
      "('e05', 'e11')\n",
      "('e05', 'e09')\n",
      "('e05', 'e07')\n",
      "('e05', 'e01')\n",
      "('e05', 'e06')\n",
      "('e05', 'e02')\n",
      "('e05', 'e03')\n",
      "('e05', 'e10')\n",
      "('e05', 'e08')\n",
      "('e05', 'e04')\n",
      "('e05', 'e05')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for i in itertools.product(np.random.choice(['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11'],size=11, replace=False),np.random.choice(['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11'],size=11, replace=False)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T03:00:19.033995Z",
     "start_time": "2021-05-12T03:00:19.029685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e11\n",
      "e04\n",
      "e07\n",
      "e03\n",
      "e09\n",
      "e10\n",
      "e06\n",
      "e08\n",
      "e02\n",
      "e01\n",
      "e05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in iterati np.random.choice(['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11'],size=11, replace=False):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
