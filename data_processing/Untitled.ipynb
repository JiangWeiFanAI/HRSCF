{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:54:45.879774Z",
     "start_time": "2021-03-14T23:54:36.938646Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.TXA6YQSD3GCQQC22GEQ54J2UDCXDXHWN.gfortran-win_amd64.dll\n",
      "E:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta, date, datetime\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "climatology_num=11\n",
    "interval_band=[90,75,50,25,10]\n",
    "\n",
    "class aaa(object):\n",
    "    def __init__(self,lead,year_generate=1997):\n",
    "        self.ensemble_access=['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']\n",
    "        self.lead_time=lead\n",
    "        self.year_generate=year_generate\n",
    "        self.files=self.get_filename_with_time_order()\n",
    "    def get_filename_with_time_order(self):\n",
    "        _files = []\n",
    "        for mm in range(1,13):\n",
    "            for dd in [1,9,17,25]:\n",
    "#                 for i in range(self.lead_time,self.lead_time+1):\n",
    "#                 for en in ['e01','e02','e03','e04','e05','e06','e07','e08','e09','e10','e11']:\n",
    "                path=[]\n",
    "                date_time=date(self.year_generate, mm, dd)\n",
    "                barra_date=date_time+timedelta(self.lead_time)\n",
    "                path.append(date_time)\n",
    "                path.append(barra_date)\n",
    "                path.append(self.lead_time)\n",
    "                _files.append(path)\n",
    "        return _files\n",
    "    def __getitem__(self,idx):\n",
    "        return self.files[idx]\n",
    "\n",
    "def load_climatology_data(l,year_generate):\n",
    "    data=aaa(l,year_generate)\n",
    "    climtology_lead_time=[]\n",
    "    climatology_data=np.load('./save/crps/climatology_'+str(year_generate)+'_all_lead_time_windows_'+str(climatology_num)+'.npy')\n",
    "#     print(climatology_data.shape)\n",
    "    dates_needs=date_range(date(year_generate, 1, 1),date(year_generate+1, 7, 29))\n",
    "    date_map=np.array(dates_needs)\n",
    "    for _,target_date,_ in data.files:\n",
    "        idx=np.where(date_map==target_date)[0]\n",
    "        climtology_lead_time.append(climatology_data[idx][0])\n",
    "    return np.array(climtology_lead_time)\n",
    "\n",
    "def date_range(start_date, end_date):\n",
    "    \"\"\"This function takes a start date and an end date as datetime date objects.\n",
    "    It returns a list of dates for each date in order starting at the first date and ending with the last date\"\"\"\n",
    "    return [start_date + timedelta(x) for x in range((end_date - start_date).days + 1)]\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "\n",
    "def table_csv_confidence(data_np,file_dir):\n",
    "    with open(file_dir+'.csv', \"w\", newline='') as file:\n",
    "        csv_file = csv.writer(file)\n",
    "        head = [\"leading\",str(interval_band[0]),str(interval_band[1]),str(interval_band[2]),str(interval_band[3]),str(interval_band[4])]\n",
    "        csv_file.writerow(head)\n",
    "\n",
    "        for lead_time in range(217):\n",
    "            line=[lead_time,data_np[0,lead_time],data_np[1,lead_time],data_np[2,lead_time],data_np[3,lead_time],data_np[4,lead_time]]\n",
    "\n",
    "            csv_file.writerow(line)\n",
    "\n",
    "def draw_plot(data,name,ylim_set=(-0.6,0.5)):\n",
    "        x=list(range(1,218))\n",
    "        data_np=np.array(data)\n",
    "        # plt.plot(x,mean_my,label=\"\",color=\"b\")#mean\n",
    "        plt.figure(dpi=100,figsize=(15,5))\n",
    "        plt.plot(x,data_np[2,:],label=\"\",color=\"r\")#median\n",
    "        plt.plot(x,[0]*217,color=\"#000000\")\n",
    "        plt.fill_between(x,data_np[0,:],data_np[1,:],color=\"#cacaca\")\n",
    "        plt.fill_between(x,data_np[1,:],data_np[2,:],color=\"#989898\")\n",
    "        plt.fill_between(x,data_np[2,:],data_np[3,:],color=\"#989898\")\n",
    "        plt.fill_between(x,data_np[3,:],data_np[4,:],color=\"#cacaca\")\n",
    "        # plt.xlim(0,217)\n",
    "        # plt.grid()\n",
    "        plt.xlabel(\" Leadtime (day)\")\n",
    "        plt.ylabel(\" CRPS_SS\")\n",
    "        plt.ylim(ylim_set[0],ylim_set[1])\n",
    "        pdf = PdfPages(name+\".pdf\")\n",
    "        pdf.savefig()\n",
    "        pdf.close()\n",
    "        plt.clf()\n",
    "        table_csv_confidence(data_np,name)\n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "def save_csv_mean(my_pr=0,my_pr_zg=0,cali=0,BI=0,climat=0,ss_my_pr=0,ss_my_pr_zg=0,ss_cali=0,ss_BI=0,lead=0,file_dir=0,first_init=0):\n",
    "    if first_init:\n",
    "        with open('table_mean_'+file_dir+'.csv', \"w\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "            head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(head)\n",
    "    else:\n",
    "        line=[lead,climat.mean(),BI.mean(),my_pr.mean(),my_pr_zg.mean(),cali.mean(),ss_BI.mean(), ss_my_pr.mean(),ss_my_pr_zg.mean(),ss_cali.mean()]\n",
    "        with open('table_mean_'+file_dir+'.csv', \"a\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "#             head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(line) \n",
    "    \n",
    "def save_csv_median(my_pr=0,my_pr_zg=0,cali=0,BI=0,climat=0,ss_my_pr=0,ss_my_pr_zg=0,ss_cali=0,ss_BI=0,lead=0,file_dir=0,first_init=0):\n",
    "    if first_init:\n",
    "        with open('table_median_'+file_dir+'.csv', \"w\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "            head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(head)\n",
    "    else:\n",
    "        line=[lead,np.median(climat),np.median(BI),np.median(my_pr),np.median(my_pr_zg),np.median(cali),np.median(ss_BI), np.median(ss_my_pr),np.median(ss_my_pr_zg),np.median(ss_cali)]\n",
    "        with open('table_median_'+file_dir+'.csv', \"a\", newline='') as file:\n",
    "            csv_file = csv.writer(file)\n",
    "#             head = [\"leading\",\"climatology_\"+str(climatology_num),'bilinear interpolation','vdsrd','vdsrd2','calibration','cspr_ss_mean_bilinearinterpolation_against_climatology','cspr_ss_mean_vdsrd_against_climatology','cspr_ss_mean_vdsrd2_against_climatology','cspr_ss_mean_calibration_against_climatology']\n",
    "            csv_file.writerow(line)           \n",
    "            \n",
    "            \n",
    "            \n",
    "def draw_confidence_figure(option='whole',year_generate=2010):\n",
    "    \n",
    "    if option == \"whole\":\n",
    "        file_path='whole_climatology_' +str(year_generate)+'_' +str(climatology_num)\n",
    "        \n",
    "        \n",
    "        save_csv_mean(file_dir=file_path,first_init=1)\n",
    "        save_csv_median(file_dir=file_path,first_init=1)\n",
    "\n",
    "        land=np.load(\"./save/crps/whole_calibration/2012/lead_time\"+str(0)+\"_whole.npy\").mean(0)\n",
    "        x=list(range(1,218))\n",
    "\n",
    "\n",
    "\n",
    "        data_my_pr_against_climatology=[]\n",
    "        data_my_pr_zg_against_climatology=[]\n",
    "        data_cali_against_climatology=[]\n",
    "        data_BI_against_climatology=[]\n",
    "\n",
    "        \n",
    "        mean_my=[]\n",
    "\n",
    "        for q in interval_band:\n",
    "            my_pr_against_climatology=[]\n",
    "            my_pr_zg_against_climatology=[]\n",
    "            cali_against_climatology=[]\n",
    "            BI_against_climatology=[]\n",
    "            \n",
    "            for lead_time in range(217):\n",
    "                if year_generate==2012:\n",
    "                    my_pr=np.load(\"./save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/wjdata/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[~np.isinf(land)]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "                else:\n",
    "                    my_pr=np.load(\"/scratch/iu60/mc7437/baseline/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[~np.isinf(land)]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[~np.isinf(land)]\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                \n",
    "                ss_my_pr= 1-my_pr/climat\n",
    "                ss_my_pr_zg=1-my_pr_zg/climat\n",
    "                ss_cali=1-cali/climat\n",
    "                ss_bi=1-BI/climat\n",
    "                \n",
    "                if q==interval_band[0]: #save four module crps and ss_crps\n",
    "                    save_csv_mean(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "                    save_csv_median(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path)\n",
    "\n",
    "#                 my_pr_against_climatology.append(np.percentile( ss_my_pr,q))\n",
    "#                 my_pr_zg_against_climatology.append(np.percentile(ss_my_pr_zg ,q))\n",
    "#                 cali_against_climatology.append(np.percentile( ss_cali,q))\n",
    "#                 BI_against_climatology.append(np.percentile(ss_bi ,q))\n",
    "\n",
    "#             data_my_pr_against_climatology.append(my_pr_against_climatology)\n",
    "#             data_my_pr_zg_against_climatology.append(my_pr_zg_against_climatology)\n",
    "#             data_cali_against_climatology.append(cali_against_climatology)\n",
    "#             data_BI_against_climatology.append(BI_against_climatology)\n",
    "\n",
    "\n",
    "#         draw_plot(data_my_pr_against_climatology,'DL_pr_only_against_climatology_'+str(year_generate)+'_'+option) \n",
    "#         draw_plot(data_my_pr_zg_against_climatology,'DL_pr_zg_against_climatology_'+str(year_generate)+'_'+option) \n",
    "#         draw_plot(data_cali_against_climatology,'calibration_against_climatology_'+str(year_generate)+'_'+option) \n",
    "#         draw_plot(data_BI_against_climatology,'BI_against_climatology_'+str(year_generate)+'_'+option) \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        file_path='station_climatology_'+str(year_generate)+'_' +str(climatology_num)\n",
    "        save_csv_mean(file_dir=file_path,first_init=1)\n",
    "        save_csv_median(file_dir=file_path,first_init=1)\n",
    "        \n",
    "        if option=='50':\n",
    "            from constant_param import station_50_index_for_size_of_hr_sr as station_dict\n",
    "        if option=='214':\n",
    "            from constant_param import station_214_index_for_size_of_hr_sr as station_dict\n",
    "            \n",
    "        land=np.load(\"./save/crps/whole_calibration/2012/lead_time\"+str(0)+\"_whole.npy\").mean(0)\n",
    "        station_index=np.zeros((land.shape))\n",
    "        for i in station_dict.keys():\n",
    "            station_index[station_dict[i]]=1\n",
    "            \n",
    "        x=list(range(1,218))\n",
    "\n",
    "\n",
    "\n",
    "        data_my_pr_against_climatology=[]\n",
    "        data_my_pr_zg_against_climatology=[]\n",
    "        data_cali_against_climatology=[]\n",
    "        data_BI_against_climatology=[]\n",
    "\n",
    "        \n",
    "        mean_my=[]\n",
    "        # for i in range(30):\n",
    "        #     a=np.load(\"./save_vdsr_pr_best_test/lead_time\"+str(i)+\"_50station_my.npy\")\n",
    "        #     mean_my.append(1-a.mean()/station50_int[i])\n",
    "        # for q in [95,75,50,25,5]:\n",
    "        #     data[q]=[]\n",
    "        for q in interval_band:\n",
    "            my_pr_against_climatology=[]\n",
    "            my_pr_zg_against_climatology=[]\n",
    "            cali_against_climatology=[]\n",
    "            BI_against_climatology=[]\n",
    "            \n",
    "            for lead_time in range(217):\n",
    "                if year_generate==2012:\n",
    "                    my_pr=np.load(\"./save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    #!!!!!!!!my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/wjdata/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[~np.isinf(land)]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[~np.isinf(land)]\n",
    "\n",
    "                else:\n",
    "                    my_pr=np.load(\"/scratch/iu60/mc7437/baseline/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    my_pr_zg=np.load(\"/scratch/iu60/mc7437/zg/save/crps/val\"+str(year_generate)[-2:]+\"/lead_time\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                    climat=load_climatology_data(lead_time,year_generate).mean(0)[~np.isinf(land)]\n",
    "                    cali=np.load(\"./save/crps/whole_calibration/\"+str(year_generate)+\"/lead_time\"+str(lead_time)+\"_whole.npy\").mean(0)[~np.isinf(land)]\n",
    "                    BI=np.load(\"./save/crps/bi_217/\"+str(year_generate)+\"/lead_time_\"+str(lead_time)+\".npy\").mean(0)[~np.isinf(land)]\n",
    "                \n",
    "\n",
    "                \n",
    "                ss_my_pr= 1-my_pr/climat\n",
    "                ss_my_pr_zg=1-my_pr_zg/climat\n",
    "                ss_cali=1-cali/climat\n",
    "                ss_bi=1-BI/climat\n",
    "                \n",
    "                if q==interval_band[0]: #save four module crps and ss_crps\n",
    "                    save_csv_mean(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "                    save_csv_median(my_pr,my_pr_zg,cali, BI,climat, ss_my_pr,ss_my_pr_zg,ss_cali,ss_bi, lead=lead_time,file_dir=file_path )\n",
    "\n",
    "#                 my_pr_against_climatology.append(np.percentile( 1-my_pr/climat,q))\n",
    "#                 my_pr_zg_against_climatology.append(np.percentile( 1-my_pr_zg/climat,q))\n",
    "#                 cali_against_climatology.append(np.percentile( 1-cali/climat,q))\n",
    "#                 BI_against_climatology.append(np.percentile( 1-BI/climat,q))\n",
    "\n",
    "#             data_my_pr_against_climatology.append(my_pr_against_climatology)\n",
    "#             data_my_pr_zg_against_climatology.append(my_pr_zg_against_climatology)\n",
    "#             data_cali_against_climatology.append(cali_against_climatology)\n",
    "#             data_BI_against_climatology.append(BI_against_climatology)\n",
    "\n",
    "#         draw_plot(data_my_pr_against_climatology,'DL_pr_only_against_climatology_'+str(year_generate)+'_'+option) \n",
    "#         draw_plot(data_my_pr_zg_against_climatology,'DL_pr_zg_against_climatology_'+str(year_generate)+'_'+option) \n",
    "#         draw_plot(data_cali_against_climatology,'calibration_against_climatology_'+str(year_generate)+'_'+option) \n",
    "#         draw_plot(data_BI_against_climatology,'BI_against_climatology_'+str(year_generate)+'_'+option) \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "                                     \n",
    "draw_confidence_figure(option='whole',year_generate=2012)\n",
    "draw_confidence_figure(option='50',year_generate=2012)\n",
    "draw_confidence_figure(option='whole',year_generate=2010)\n",
    "draw_confidence_figure(option='50',year_generate=2010)\n",
    "draw_confidence_figure(option='whole',year_generate=1997)\n",
    "draw_confidence_figure(option='50',year_generate=1997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T05:05:11.243523Z",
     "start_time": "2021-03-14T05:05:11.180189Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "get_access_SR_data(start_date=date(2010, 1, 1),    end_date=date(2010,12,25),net_path='./model/val10/best_train_30.pth')\n",
    "# get_access_SR_data(start_date=date(1997, 1, 1),    end_date=date(1997,12,25),net_path='/scratch/iu60/wj1671/HRSCF_v1/save/model/val97/best_train_30.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:56:13.702178Z",
     "start_time": "2021-03-14T23:56:13.659232Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'vdsr' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7531b74eb239>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnet_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../save/model/val10/best_train_30.pth'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvdsr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# copy state_dict so _load_from_state_dict can modify it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_metadata'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[0mstate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[0mstate_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Users\\Weifa\\Anaconda3\\envs\\py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    777\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 779\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleAttributeError\u001b[0m: 'vdsr' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net_state=torch.load('../save/model/val10/best_train_30.pth',map_location=device)['model'].state_dict()\n",
    "net = vdsr().to(device)\n",
    "net.load_state_dict(net_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:54:54.467703Z",
     "start_time": "2021-03-14T23:54:53.876718Z"
    }
   },
   "outputs": [],
   "source": [
    "# net=torch.load('../save/model/val10/best_train_30.pth',map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T23:55:21.317991Z",
     "start_time": "2021-03-14T23:55:21.313003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vdsr(\n",
       "  (residual_layer): Sequential(\n",
       "    (0): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Conv_ReLU_Block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (input): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (output): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net['model']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
